{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bec4229",
   "metadata": {},
   "source": [
    "# Integration of Cuts into DataHandler:\n",
    "\n",
    "The `DataHandler` class should be instantiated with a `cuts` object. The `cuts` object would be a `JSON` file that has the following structure.\n",
    "\n",
    "## Cuts JSON Structure:\n",
    "\n",
    "```json\n",
    "name (dtype -> string (e.g. \"cut1\")):\n",
    "    {\n",
    "        function: dtype -> string (e.g. \"trimDF\"),\n",
    "        term: dtype -> string (e.g. \"clusterEta\"),\n",
    "        operation: dtype -> string (e.g. \">\"),\n",
    "        value: dtype -> float/int (e.g. 0.8, 2),\n",
    "\n",
    "    }\n",
    "```\n",
    "\n",
    "The `JSON` file can contain as many of such cuts as required. \n",
    "\n",
    "**IMPORTANT**\n",
    "1. An empty `JSON` file would imply no cuts.\n",
    "2. Cuts will be processed in the order they are presented in the `JSON` file.\n",
    "\n",
    "## Cuts Available\n",
    "\n",
    "The following cuts are available within the program.\n",
    "\n",
    "`trimDF`, `trimAbsDF`, `summedEnergyCut`\n",
    "\n",
    "You can define your own custom cuts in `Cuts.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d5f6b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## DataHandler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1b4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from Cuts import *\n",
    "\n",
    "def normalizeDF(df):\n",
    "    df_norm = df.subtract(df.mean())\n",
    "    df_norm = df_norm.divide(df.std())\n",
    "    return df_norm\n",
    "\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self, path2test, path2train, path2list_inputs, cuts_dir):\n",
    "        self.path2test = path2test\n",
    "        self.path2train = path2train\n",
    "        self.list_inputs = self.getListInputs(path2list_inputs)\n",
    "        \n",
    "        self.train_raw = self.getAllTrainDF()\n",
    "        self.test_raw = self.getAllTestDF()\n",
    "        self.allColumns = self.train_raw.columns\n",
    "        \n",
    "        self.train_all_normed = normalizeDF(self.train_raw)\n",
    "        self.test_all_normed = normalizeDF(self.test_raw)\n",
    "        \n",
    "        self.train_df = self.getTrainingData()\n",
    "        self.test_df = self.getTestingData()\n",
    "        self.target_df = self.train_raw[\"cluster_ENG_CALIB_TOT\"]\n",
    "        \n",
    "        self.processCuts(cuts_dir, self.train_all_normed)\n",
    "    \n",
    "    def processCuts(self, cuts_dir, df):\n",
    "        cuts_df = pd.read_json(cuts_dir)\n",
    "        if len(cuts_df) == 0:\n",
    "            print(\"No cuts applied...\")\n",
    "            return\n",
    "        else:\n",
    "            c = Cuts(cuts_df, df)\n",
    "            df = c.getCuts(df)\n",
    "            self.train_df = self.getTrainingDataFromCutDF(df)\n",
    "            self.test_df = self.getTestingDataFromCutDF(df)\n",
    "            self.target_df = self.getTargetDatafromCutDF(df, self.train_raw)\n",
    "            \n",
    "    def getTargetDatafromCutDF(self, df, test_df):\n",
    "        indices = list(df.index.values)\n",
    "        df = test_df.iloc[indices]\n",
    "        return df[\"cluster_ENG_CALIB_TOT\"]\n",
    "    \n",
    "    def getTestingDataFromCutDF(self, df):\n",
    "        test_df = df[self.list_inputs]\n",
    "        normed_df = normalizeDF(test_df)\n",
    "        return normed_df\n",
    "\n",
    "    def getTrainingDataFromCutDF(self, df):\n",
    "        train_df = df[self.list_inputs]\n",
    "        normed_df = normalizeDF(train_df)\n",
    "        return normed_df\n",
    "        \n",
    "    def getListInputs(self, path2inputs): #gets list inputs data\n",
    "        with open(path2inputs, newline='') as f:\n",
    "            reader = csv.reader(f)\n",
    "            data = list(reader)\n",
    "        data = list(np.array(data).flatten())\n",
    "        return data\n",
    "    \n",
    "    def getAllTestDF(self): #gets testing data frame\n",
    "        test_all = pd.read_csv(self.path2test)\n",
    "        return test_all\n",
    "\n",
    "    def getAllTrainDF(self):#gets training data frame\n",
    "        train_all = pd.read_csv(self.path2train)\n",
    "        return train_all\n",
    "\n",
    "    def getAllDataColumns(self): #gets the names of the data columns in the data frame\n",
    "        columns = pd.read_csv(self.path2test, nrows=1)\n",
    "        return columns\n",
    "\n",
    "    def getTestingData(self):#gets list inputs testing data from normalized data frame\n",
    "        test_df = self.test_raw[self.list_inputs]\n",
    "        normed_df = normalizeDF(test_df)\n",
    "        return normed_df\n",
    "\n",
    "    def getTrainingData(self):#gets list inputs training data from normalized data frame\n",
    "        train_df = self.train_raw[self.list_inputs]\n",
    "        normed_df = normalizeDF(train_df)\n",
    "        return normed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732d394",
   "metadata": {},
   "source": [
    "## Cuts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b3aa6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Cuts:\n",
    "    \n",
    "    def __init__(self, cuts_df, df):\n",
    "        self.cuts_df = cuts_df\n",
    "        self.df = df\n",
    "        \n",
    "    def getCuts(self, df):\n",
    "        for col in self.cuts_df.columns:\n",
    "            data = self.cuts_df[col].values\n",
    "            fname = data[0]\n",
    "            term = data[1]\n",
    "            operation = data[2]\n",
    "            value = data[3]\n",
    "            df = getattr(self, fname)(df, term, value, operation, col) #selects the corresponding func from the json\n",
    "            # and executes\n",
    "            print(\"Size of dataframe: {}\\n\".format(len(df)))\n",
    "        return df\n",
    "    \n",
    "    def summedEnergyCut(self, df,term,value,operation, col):\n",
    "        print(\"Applying Cut: {}\".format(col, term, operation, value))\n",
    "        df.sort_values(by=['eventNumber'],inplace=True)\n",
    "        cname = \"sum\"+term\n",
    "        df[cname] = value*df.groupby('eventNumber')[term].transform('sum')\n",
    "\n",
    "        if operation == \"<\":\n",
    "            df = df[df[term] < df[cname]]\n",
    "        elif operation == \">\":\n",
    "            df = df[df[term] > df[cname]]\n",
    "        elif operation == \"==\":\n",
    "            df = df[df[term] == df[cname]]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def trimDF(self, df,term,value,operation, col):\n",
    "        print(\"Applying Cut: {}\".format(col, term, operation, value))\n",
    "        \n",
    "        if operation == \"<\":\n",
    "            df = df[df[term] < value]\n",
    "        elif operation == \">\":\n",
    "            df = df[df[term] > value]\n",
    "        elif operation == \"==\":\n",
    "            df = df[df[term] == value]\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def trimAbsDF(self, df,term,value,operation, col):\n",
    "        print(\"Applying Cut: {}\".format(col, term, operation, value))\n",
    "        \n",
    "        if operation == \"<\":\n",
    "            df = df[abs(df[term]) < value]\n",
    "        elif operation == \">\":\n",
    "            df = df[abs(df[term]) > value]\n",
    "        elif operation == \"==\":\n",
    "            df = df[abs(df[term]) == value]\n",
    "            \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdf4e1b",
   "metadata": {},
   "source": [
    "## Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66ffa73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_json_dir = 'cuts/basic_cuts.json'\n",
    "no_cuts_json_dir = 'cuts/example_cut1.json'\n",
    "\n",
    "test_csv_dir = \"data/test.csv\"\n",
    "train_csv_dir = \"data/train.csv\"\n",
    "inputs_dir = \"inputs/FelixInputs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5901ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Cut: summedEnergyCut\n",
      "Size of dataframe: 993972\n",
      "\n",
      "Applying Cut: etaCut\n",
      "Size of dataframe: 511149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cut_data = DataHandler(test_csv_dir, train_csv_dir, inputs_dir, cuts_json_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc81ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cuts applied...\n"
     ]
    }
   ],
   "source": [
    "no_cut_data = DataHandler(test_csv_dir, train_csv_dir, inputs_dir, no_cuts_json_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9938b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nctrain_df = no_cut_data.train_df\n",
    "nctrain_all_df = no_cut_data.train_raw\n",
    "nctest_df = no_cut_data.test_df\n",
    "nctarget_df = no_cut_data.target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68c677f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrain_df = cut_data.train_df\n",
    "ctrain_all_df = cut_data.train_raw\n",
    "ctest_df = cut_data.test_df\n",
    "ctarget_df = cut_data.target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fd4abbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511149, 511149)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ctrain_df), len(ctarget_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a771bb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2629411, 2629411)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nctrain_df), len(nctarget_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ea18bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summedEnergyCut(df,term,value,operation, col):\n",
    "    print(\"Applying Cut: {}\".format(col, term, operation, value))\n",
    "    df.sort_values(by=['eventNumber'],inplace=True)\n",
    "    cname = \"sum\"+term\n",
    "    df[cname] = value*df.groupby('eventNumber')[term].transform('sum')\n",
    "\n",
    "    if operation == \"<\":\n",
    "        df = df[df[term] < df[cname]]\n",
    "    elif operation == \">\":\n",
    "        df = df[df[term] > df[cname]]\n",
    "    elif operation == \"==\":\n",
    "        df = df[df[term] == df[cname]]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d237d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374748e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
